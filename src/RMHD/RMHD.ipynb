{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pandas in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scipy in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in /Users/dominicchang/Software/SMART-GRMHD/lib/python3.12/site-packages (from scipy) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Import Custom Activation Layers\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from activationLayers import *\n",
    "\n",
    "# Import RMHD Equations\n",
    "from RMHDEquations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"mps\") #(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Neural Network\n",
    "class RMHDPINN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, n_hidden, hidden_width, activation=TrainableTanh(), output_projection=FinalActivation()):\n",
    "        super(RMHDPINN, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_size\n",
    "        self.output_dim = output_size\n",
    "        self.hidden_dim = hidden_width\n",
    "        self.num_layers = n_hidden\n",
    "        \n",
    "        # Define U and V layers separately\n",
    "        self.U_layer = nn.Linear(input_size, hidden_width)\n",
    "        self.V_layer = nn.Linear(input_size, hidden_width)\n",
    "        \n",
    "        # Define hidden and output layers\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_width, hidden_width) for _ in range(n_hidden)])\n",
    "        self.output_layer = nn.Linear(hidden_width, output_size)\n",
    "        \n",
    "        # Set activation function\n",
    "        self.phi = activation\n",
    "        self.output_projection = output_projection\n",
    "        \n",
    "    def forward(self, t, x):\n",
    "        t = t.unsqueeze(1) if len(t.shape) == 1 else t\n",
    "        x = x.unsqueeze(1) if len(x.shape) == 1 else x\n",
    "        X = torch.cat([x, t], dim=1)\n",
    "        U_t = self.phi(self.U_layer(X))\n",
    "        V_t = self.phi(self.V_layer(X))\n",
    "        H = U_t  # initial value for H\n",
    "\n",
    "        for layer in self.hidden_layers:\n",
    "            Z = self.phi(layer(H))\n",
    "            H = (1 - Z) * U_t + Z * V_t\n",
    "\n",
    "        output = self.output_layer(H)\n",
    "        # Print the shape of the tensor before it's passed to the FinalActivation\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "# Initialization\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMHDPINN(\n",
      "  (U_layer): Linear(in_features=2, out_features=16, bias=True)\n",
      "  (V_layer): Linear(in_features=2, out_features=16, bias=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0-3): 4 x Linear(in_features=16, out_features=16, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=16, out_features=5, bias=True)\n",
      "  (phi): TrainableTanh()\n",
      "  (output_projection): FinalActivation()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0162,  0.1883,  0.0729,  0.1637,  0.1323],\n",
       "        [-0.0103,  0.1603,  0.0829,  0.1464,  0.1216],\n",
       "        [ 0.0061,  0.2123,  0.1506, -0.0107,  0.0963],\n",
       "        [-0.0140,  0.1678,  0.1064,  0.1014,  0.1100],\n",
       "        [-0.0152,  0.1751,  0.1013,  0.1103,  0.1143],\n",
       "        [-0.0061,  0.1160,  0.1201,  0.0811,  0.0950],\n",
       "        [ 0.0061,  0.0335,  0.1767, -0.0112,  0.0548],\n",
       "        [ 0.0284,  0.2330,  0.1798, -0.0766,  0.0863],\n",
       "        [ 0.0096,  0.0198,  0.1611,  0.0120,  0.0677],\n",
       "        [ 0.0127,  0.0081,  0.1621,  0.0094,  0.0678]], device='mps:0',\n",
       "       grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "depth = 4\n",
    "width = 16\n",
    "activation = FinalActivation()\n",
    "model = RMHDPINN(input_size=2, output_size=5, n_hidden=depth, hidden_width=width, activation=TrainableTanh(), output_projection=activation).to(device)\n",
    "print(model)\n",
    "model(torch.rand(10,device=device), torch.rand(10,device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_condition(x):\n",
    "    condition1 = torch.tensor([1.0,0.0,1.0,0.0,1.0], device=device)\n",
    "    condition2 = torch.tensor([0.125,0.0,-1.0,0.0,0.1], device=device)\n",
    "    newx = torch.flatten(x).to(device)\n",
    "    return torch.outer(newx<0, condition1) + torch.outer(newx>=0, condition2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(outputs, inputs, order = 1, device=device):\n",
    "    if order == 1:\n",
    "        return torch.autograd.grad(outputs, inputs, grad_outputs=torch.ones_like(outputs), create_graph=True)[0]\n",
    "    elif order > 1:\n",
    "        return gradients(gradients(outputs, inputs, 1), inputs, order - 1) # Recursively take gradients\n",
    "    else:\n",
    "        return outputs\n",
    "\n",
    "def rmhd_residual(pred,t,x):\n",
    "    u_t= gradients(conserved_alfredo(pred),t)\n",
    "    u_x= gradients(currents_alfredo(pred),x)\n",
    "    return u_t + u_x\n",
    "\n",
    "\n",
    "def random_domain(num_samples, t_range, x_range):\n",
    "    t_random = torch.zeros(size=(num_samples, 1), device=device).uniform_(*t_range)\n",
    "    x_random = torch.zeros(size=(num_samples, 1), device=device).uniform_(*x_range)\n",
    "    t_random.requires_grad = True\n",
    "    x_random.requires_grad = True\n",
    "    return t_random, x_random\n",
    "\n",
    "\n",
    "\n",
    "def random_boundary(num_samples, t_range, x_range, initial_to_boundary_ratio = 0.5):\n",
    "    num_initial = int(initial_to_boundary_ratio * num_samples)\n",
    "    num_boundary = num_samples - num_initial\n",
    "    t_min, t_max = t_range\n",
    "\n",
    "    # Generate initial condition samples\n",
    "    t_initial = torch.zeros(size=(num_initial, 1), device=device)\n",
    "    x_initial = torch.zeros(size=(num_initial, 1), device=device).uniform_(*x_range)\n",
    "    u_initial = initial_condition(x_initial)\n",
    "\n",
    "    # Generate boundary condition samples\n",
    "    t_boundary = torch.zeros(size=(num_boundary, 1), device=device).uniform_(*t_range)\n",
    "\n",
    "    # We assume x_range = (-1, 1) here\n",
    "    x_boundary = 2 * torch.randint(0, 2, size=(num_boundary, 1), device=device) - 1\n",
    "    u_boundary = initial_condition(x_boundary)#np.zeros((num_boundary, 1))\n",
    "\n",
    "    return torch.tensor(t_initial, dtype=torch.float32), torch.tensor(x_initial, dtype=torch.float32), torch.tensor(u_initial, dtype=torch.float32), \\\n",
    "           torch.tensor(t_boundary, dtype=torch.float32), torch.tensor(x_boundary, dtype=torch.float32), torch.tensor(u_boundary, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "model = RMHDPINN(input_size=2, output_size=5, n_hidden=depth, hidden_width=width, activation=TrainableTanh(), output_projection=activation).to(device)\n",
    "#model = PINN(input_size=2, output_size=5, n_hidden=depth, hidden_width=width, activation=activation)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, eps=1e-4)\n",
    "boundary_criterion = nn.MSELoss()\n",
    "initial_criterion = nn.MSELoss()\n",
    "domain_criterion = nn.MSELoss()\n",
    "intermediate_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/qsgfh7hj7csg_x4f7kcm2p9r0000gq/T/ipykernel_14206/2172649982.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(t_initial, dtype=torch.float32), torch.tensor(x_initial, dtype=torch.float32), torch.tensor(u_initial, dtype=torch.float32), \\\n",
      "/var/folders/69/qsgfh7hj7csg_x4f7kcm2p9r0000gq/T/ipykernel_14206/2172649982.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(t_boundary, dtype=torch.float32), torch.tensor(x_boundary, dtype=torch.float32), torch.tensor(u_boundary, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 0.28771740198135376\n",
      "Epoch: 200, Loss: 0.14189381897449493\n",
      "Epoch: 300, Loss: 0.14674954116344452\n",
      "Epoch: 400, Loss: 0.1235985979437828\n",
      "Epoch: 500, Loss: 0.14424970746040344\n",
      "Epoch: 600, Loss: 0.17627273499965668\n",
      "Epoch: 700, Loss: 0.11985944956541061\n",
      "Epoch: 800, Loss: 0.11424925923347473\n",
      "Epoch: 900, Loss: 0.10406769812107086\n",
      "Epoch: 1000, Loss: 0.12069244682788849\n",
      "Epoch: 1100, Loss: 0.10208024829626083\n",
      "Epoch: 1200, Loss: 0.11580085009336472\n",
      "Epoch: 1300, Loss: 0.10521267354488373\n",
      "Epoch: 1400, Loss: 0.09301437437534332\n",
      "Epoch: 1500, Loss: 0.11514314264059067\n",
      "Epoch: 1600, Loss: 0.09712431579828262\n",
      "Epoch: 1700, Loss: 0.09742429852485657\n",
      "Epoch: 1800, Loss: 0.10269646346569061\n",
      "Epoch: 1900, Loss: 0.10128052532672882\n",
      "Epoch: 2000, Loss: 0.0756104588508606\n",
      "Epoch: 2100, Loss: 0.10469011962413788\n",
      "Epoch: 2200, Loss: 0.09478065371513367\n",
      "Epoch: 2300, Loss: 0.083088718354702\n",
      "Epoch: 2400, Loss: 0.09573033452033997\n",
      "Epoch: 2500, Loss: 0.09006468206644058\n",
      "Epoch: 2600, Loss: 0.08343765884637833\n",
      "Epoch: 2700, Loss: 0.09472493082284927\n",
      "Epoch: 2800, Loss: 0.09809283167123795\n",
      "Epoch: 2900, Loss: 0.08877899497747421\n",
      "Epoch: 3000, Loss: 0.09115908294916153\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3000\n",
    "model.train()\n",
    "\n",
    "x_range, t_range = [-1, 1], [0, 1]\n",
    "loss_history = []\n",
    "domain_loss_history = []\n",
    "initial_loss_history = []\n",
    "boundary_loss_history = []\n",
    "a_history = []\n",
    "b_history = []\n",
    "c_history = []\n",
    "gradient_history = []\n",
    "\n",
    "# Initialize lambda values\n",
    "lambda_initial = 1.0\n",
    "lambda_boundary = 1.0\n",
    "\n",
    "max_schedule_steps = 1000\n",
    "n = 100\n",
    "for epoch in range(1, num_epochs + 1, max_schedule_steps):\n",
    "    n += 7\n",
    "    domain_samples = n**2\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] *= 3/4\n",
    "    for step in range(0, max_schedule_steps):\n",
    "        boundary_samples = 300  # You can change this value\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        domain_t, domain_x = random_domain(domain_samples, t_range, x_range)\n",
    "        initial_t, initial_x, initial_u, boundary_t, boundary_x, boundary_u = random_boundary(boundary_samples, t_range, x_range, 0.5)\n",
    "        domain_prediction = model(domain_t, domain_x)\n",
    "        domain_residual = rmhd_residual(domain_prediction, domain_t, domain_x)\n",
    "        initial_prediction = model(initial_t, initial_x)\n",
    "        boundary_prediction = model(boundary_t, boundary_x)\n",
    "\n",
    "        domain_loss = domain_criterion(domain_residual, torch.zeros_like(domain_residual))\n",
    "        initial_loss = initial_criterion(initial_prediction, initial_u)\n",
    "        boundary_loss = boundary_criterion(boundary_prediction, boundary_u)\n",
    "\n",
    "        # # Step 3: Compute total loss and backpropagate\n",
    "        loss = 10*domain_loss + lambda_initial * initial_loss + lambda_boundary * boundary_loss\n",
    "\n",
    "        # Compute backward and update model parameters as usual\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        current_grads = [p.grad.clone() for p in model.parameters()]\n",
    "        gradient_history.append(current_grads)\n",
    "        \n",
    "        loss_history.append(loss.item())\n",
    "        domain_loss_history.append(domain_loss.item())\n",
    "        initial_loss_history.append(initial_loss.item())\n",
    "        boundary_loss_history.append(boundary_loss.item())\n",
    "\n",
    "        \n",
    "        if (epoch+step) % 100 == 0:\n",
    "            print(f\"Epoch: {epoch+step}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2557, -0.0077, -0.7002,  0.0035,  0.1385],\n",
       "        [ 0.6894,  0.0079, -0.2157,  0.0672,  0.4347],\n",
       "        [ 0.7949,  0.0342, -0.1289,  0.0829,  0.4856],\n",
       "        ...,\n",
       "        [ 0.4133,  0.0120, -0.5600,  0.0412,  0.2470],\n",
       "        [ 0.6123, -0.0415, -0.0938,  0.0486,  0.4700],\n",
       "        [ 0.8962,  0.0240,  0.0207,  0.0861,  0.5680]], device='mps:0',\n",
       "       grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(domain_t, domain_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpcolormesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdomain_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdomain_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain_x\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Software/SMART-GRMHD/lib/python3.12/site-packages/matplotlib/pyplot.py:3493\u001b[0m, in \u001b[0;36mpcolormesh\u001b[0;34m(alpha, norm, cmap, vmin, vmax, shading, antialiased, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3480\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mpcolormesh)\n\u001b[1;32m   3481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpcolormesh\u001b[39m(\n\u001b[1;32m   3482\u001b[0m     \u001b[38;5;241m*\u001b[39margs: ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3491\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3492\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m QuadMesh:\n\u001b[0;32m-> 3493\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpcolormesh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3494\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshading\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshading\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mantialiased\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mantialiased\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3502\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3503\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3505\u001b[0m     sci(__ret)\n\u001b[1;32m   3506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/Software/SMART-GRMHD/lib/python3.12/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/Software/SMART-GRMHD/lib/python3.12/site-packages/matplotlib/axes/_axes.py:6292\u001b[0m, in \u001b[0;36mAxes.pcolormesh\u001b[0;34m(self, alpha, norm, cmap, vmin, vmax, shading, antialiased, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6289\u001b[0m shading \u001b[38;5;241m=\u001b[39m shading\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m   6290\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medgecolors\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 6292\u001b[0m X, Y, C, shading \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pcolorargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpcolormesh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6293\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mshading\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshading\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6294\u001b[0m coords \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([X, Y], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   6296\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnap\u001b[39m\u001b[38;5;124m'\u001b[39m, mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpcolormesh.snap\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Software/SMART-GRMHD/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5815\u001b[0m, in \u001b[0;36mAxes._pcolorargs\u001b[0;34m(self, funcname, shading, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5810\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mis_masked(X) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mis_masked(Y):\n\u001b[1;32m   5811\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   5812\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx and y arguments to pcolormesh cannot have \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   5813\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnon-finite values or be of type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   5814\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy.ma.MaskedArray with masked values\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 5815\u001b[0m     nrows, ncols \u001b[38;5;241m=\u001b[39m C\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   5816\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5817\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _api\u001b[38;5;241m.\u001b[39mnargs_error(funcname, takes\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1 or 3\u001b[39m\u001b[38;5;124m\"\u001b[39m, given\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(args))\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SmartGRMHD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
