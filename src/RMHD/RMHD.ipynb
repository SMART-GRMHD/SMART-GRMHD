{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Import Custom Activation Layers\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from activationLayers import *\n",
    "\n",
    "# Import RMHD Equations\n",
    "from RMHDEquations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Neural Network\n",
    "\n",
    "class RMHDPINN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, n_hidden, hidden_width, activation=TrainableTanh(), output_projection=FinalActivation()):\n",
    "        super(RMHDPINN, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_size\n",
    "        self.output_dim = output_size\n",
    "        self.hidden_dim = hidden_width\n",
    "        self.num_layers = n_hidden\n",
    "        \n",
    "        # Define U and V layers separately\n",
    "        self.U_layer = nn.Linear(input_size, hidden_width)\n",
    "        self.V_layer = nn.Linear(input_size, hidden_width)\n",
    "        \n",
    "        # Define hidden and output layers\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_width, hidden_width) for _ in range(n_hidden)])\n",
    "        self.output_layer = nn.Linear(hidden_width, output_size)\n",
    "        \n",
    "        # Set activation function\n",
    "        self.phi = activation\n",
    "        self.output_projection = output_projection\n",
    "        \n",
    "    def forward(self, t, x):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the neural network.\n",
    "\n",
    "        Args:\n",
    "            t (torch.Tensor): The time argument.\n",
    "            x (torch.Tensor): The position argument.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The primitives for the 1-dimensional RMHD equations.\n",
    "\n",
    "        \"\"\"\n",
    "        t = t.unsqueeze(1) if len(t.shape) == 1 else t\n",
    "        x = x.unsqueeze(1) if len(x.shape) == 1 else x\n",
    "        X = torch.cat([x, t], dim=1)\n",
    "        U_t = self.phi(self.U_layer(X))\n",
    "        V_t = self.phi(self.V_layer(X))\n",
    "        H = U_t  # initial value for H\n",
    "\n",
    "        for layer in self.hidden_layers:\n",
    "            Z = self.phi(layer(H))\n",
    "            H = (1 - Z) * U_t + Z * V_t\n",
    "\n",
    "        output = self.output_projection(self.output_layer(H))\n",
    "        # Print the shape of the tensor before it's passed to the FinalActivation\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "# Initialization\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "depth = 4\n",
    "width = 16\n",
    "activation = FinalActivation()\n",
    "model = RMHDPINN(input_size=2, output_size=7, n_hidden=depth, hidden_width=width, activation=TrainableTanh(), output_projection=activation).to(device)\n",
    "print(model)\n",
    "model(torch.rand(10,device=device), torch.rand(10,device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function generates the initial conditions for primitives from conserved quantities.\n",
    "\n",
    "Parameters:\n",
    "- x (torch.Tensor): The spatial coordinate.\n",
    "\n",
    "Returns:\n",
    "- torch.Tensor: The initial conditions for primitives.\n",
    "\n",
    "\"\"\"\n",
    "def initial_condition(x):\n",
    "    # Conserved:  D, v_x, v_y, v_z, By, B_z, p\n",
    "    # Primitives: rho, mx, my, m_z, By, B_z E\n",
    "    condition1 = torch.tensor([1.0, 0.0, 0.0, 0.0, 6.0, 6.0, 30.0], device=device)\n",
    "    condition2 = torch.tensor([1.0, 0.0, 0.0, 0.0, 0.7, 0.7, 1.0], device=device)\n",
    "    newx = torch.flatten(x).to(device)\n",
    "    return torch.outer(newx<0, condition1) + torch.outer(newx>=0, condition2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(outputs, inputs, order = 1, device=device):\n",
    "    if order == 1:\n",
    "        return torch.autograd.grad(outputs, inputs, grad_outputs=torch.ones_like(outputs), create_graph=True)[0]\n",
    "    elif order > 1:\n",
    "        return gradients(gradients(outputs, inputs, 1), inputs, order - 1) # Recursively take gradients\n",
    "    else:\n",
    "        return outputs\n",
    "\n",
    "def rmhd_residual(pred,t,x):\n",
    "    u_t= gradients(conserved_alfredo(pred),t)\n",
    "    u_x= gradients(currents_alfredo(pred),x)\n",
    "    return u_t + u_x\n",
    "\n",
    "\n",
    "def random_domain(num_samples, t_range, x_range):\n",
    "    t_random = torch.zeros(size=(num_samples, 1), device=device).uniform_(*t_range)\n",
    "    x_random = torch.zeros(size=(num_samples, 1), device=device).uniform_(*x_range)\n",
    "    t_random.requires_grad = True\n",
    "    x_random.requires_grad = True\n",
    "    return t_random, x_random\n",
    "\n",
    "def random_boundary(num_samples, t_range, x_range, initial_to_boundary_ratio = 0.5):\n",
    "    num_initial = int(initial_to_boundary_ratio * num_samples)\n",
    "    num_boundary = num_samples - num_initial\n",
    "    t_min, t_max = t_range\n",
    "\n",
    "    # Generate initial condition samples\n",
    "    t_initial = torch.zeros(size=(num_initial, 1), device=device)\n",
    "    x_initial = torch.zeros(size=(num_initial, 1), device=device).uniform_(*x_range)\n",
    "    u_initial = initial_condition(x_initial)\n",
    "\n",
    "    # Generate boundary condition samples\n",
    "    t_boundary = torch.zeros(size=(num_boundary, 1), device=device).uniform_(*t_range)\n",
    "\n",
    "    # We assume x_range = (-1, 1) here\n",
    "    x_boundary = 2 * torch.randint(0, 2, size=(num_boundary, 1), device=device) - 1\n",
    "    u_boundary = initial_condition(x_boundary)#np.zeros((num_boundary, 1))\n",
    "\n",
    "    return torch.tensor(t_initial, dtype=torch.float32), torch.tensor(x_initial, dtype=torch.float32), torch.tensor(u_initial, dtype=torch.float32), \\\n",
    "           torch.tensor(t_boundary, dtype=torch.float32), torch.tensor(x_boundary, dtype=torch.float32), torch.tensor(u_boundary, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "model = RMHDPINN(input_size=2, output_size=7, n_hidden=depth, hidden_width=width, activation=TrainableTanh(), output_projection=activation).to(device)\n",
    "#model = PINN(input_size=2, output_size=5, n_hidden=depth, hidden_width=width, activation=activation)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, eps=1e-4)\n",
    "boundary_criterion = nn.MSELoss()\n",
    "initial_criterion = nn.MSELoss()\n",
    "domain_criterion = nn.MSELoss()\n",
    "intermediate_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "model.train()\n",
    "\n",
    "x_range, t_range = [-0.5, 0.5], [0, 1]\n",
    "loss_history = []\n",
    "domain_loss_history = []\n",
    "initial_loss_history = []\n",
    "boundary_loss_history = []\n",
    "a_history = []\n",
    "b_history = []\n",
    "c_history = []\n",
    "gradient_history = []\n",
    "\n",
    "# Initialize lambda values\n",
    "lambda_initial = 10.0\n",
    "lambda_boundary = 1.0\n",
    "\n",
    "max_schedule_steps = 5000\n",
    "n = 100\n",
    "for epoch in range(1, num_epochs + 1, max_schedule_steps):\n",
    "    n += 7\n",
    "    domain_samples = n**2\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] *= 3/4\n",
    "    for step in range(0, max_schedule_steps):\n",
    "        boundary_samples = 300  # You can change this value\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        domain_t, domain_x = random_domain(domain_samples, t_range, x_range)\n",
    "        initial_t, initial_x, initial_u, boundary_t, boundary_x, boundary_u = random_boundary(boundary_samples, t_range, x_range, 0.5)\n",
    "        domain_prediction = model(domain_t, domain_x)\n",
    "        domain_residual = rmhd_residual(domain_prediction, domain_t, domain_x)\n",
    "        initial_prediction = model(initial_t, initial_x)\n",
    "        boundary_prediction = model(boundary_t, boundary_x)\n",
    "\n",
    "        domain_loss = domain_criterion(domain_residual, torch.zeros_like(domain_residual))\n",
    "        initial_loss = initial_criterion(initial_prediction, initial_u)\n",
    "        boundary_loss = boundary_criterion(boundary_prediction, boundary_u)\n",
    "\n",
    "        # # Step 3: Compute total loss and backpropagate\n",
    "        loss = domain_loss + lambda_initial * initial_loss + lambda_boundary * boundary_loss\n",
    "\n",
    "        # Compute backward and update model parameters as usual\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        current_grads = [p.grad.clone() for p in model.parameters()]\n",
    "        gradient_history.append(current_grads)\n",
    "        \n",
    "        loss_history.append(loss.item())\n",
    "        domain_loss_history.append(domain_loss.item())\n",
    "        initial_loss_history.append(initial_loss.item())\n",
    "        boundary_loss_history.append(boundary_loss.item())\n",
    "\n",
    "        \n",
    "        if (epoch+step) % 100 == 0:\n",
    "            print(f\"Epoch: {epoch+step}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(domain_t, domain_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(domain_t, domain_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "tplot = 0  # 0.147\n",
    "\n",
    "x = np.linspace(-0.5, 0.5, 100)\n",
    "t = np.linspace(tplot, tplot, 1)\n",
    "\n",
    "t, x = np.meshgrid(t, x)\n",
    "t, x = t.flatten(), x.flatten()\n",
    "t, x = torch.Tensor(t).to(device), torch.Tensor(x).to(device)\n",
    "# numeric = inter_condition(tplot, x)\n",
    "# numeric = numeric.reshape(100, 7)\n",
    "prediction = model(t, x).detach()\n",
    "prediction = prediction.reshape(100, 7)\n",
    "\n",
    "# plt.imshow(prediction)\n",
    "\n",
    "for i in range(7):\n",
    "\n",
    "    # plt.plot(x.cpu().numpy(), numeric[:, i].cpu().flatten().numpy())\n",
    "    plt.plot(x.cpu().numpy(), prediction[:, i].cpu().flatten().numpy())\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "tplot = 0.0 # 0.147\n",
    "\n",
    "x = np.linspace(-0.5, 0.5, 100)\n",
    "t = np.linspace(tplot, tplot, 1)\n",
    "\n",
    "t, x = np.meshgrid(t, x)\n",
    "t, x = t.flatten(), x.flatten()\n",
    "t, x = torch.Tensor(t).to(device), torch.Tensor(x).to(device)\n",
    "# numeric = inter_condition(tplot, x)\n",
    "# numeric = numeric.reshape(100, 7)\n",
    "prediction = model(t, x).detach()\n",
    "prediction = prediction.reshape(100, 7)\n",
    "\n",
    "# plt.imshow(prediction)\n",
    "\n",
    "for i in range(7):\n",
    "\n",
    "    # plt.plot(x.cpu().numpy(), numeric[:, i].cpu().flatten().numpy())\n",
    "    plt.plot(x.cpu().numpy(), prediction[:, i].cpu().flatten().numpy())\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
